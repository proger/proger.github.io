[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/counter/counter.html",
    "href": "posts/counter/counter.html",
    "title": "How To Count Experience",
    "section": "",
    "text": "When performing exploration of environments we’d like to know how many times we’ve been in the current state.\nimport math\nimport matplotlib.pyplot as plt\nimport string\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.manual_seed(0)\ntorch.set_grad_enabled(False);"
  },
  {
    "objectID": "posts/counter/counter.html#idea-0-count-numbers",
    "href": "posts/counter/counter.html#idea-0-count-numbers",
    "title": "How To Count Experience",
    "section": "Idea 0: count numbers",
    "text": "Idea 0: count numbers\nAssume all experience is finite and discrete.\nIn this example, given a buffer x of \\(T=7\\) experience of kinds \\([0..10)\\) exclusive, use torch.unique to count occurrences.\n\nT = 7\nexperience = torch.randint(0, 10, (T,))\nexperience\n\nunique_experience, counts = torch.unique(experience, return_counts=True)\nhisto = torch.zeros(10, dtype=torch.long).scatter_(0, unique_experience, counts)\nplt.subplots(1, 1, figsize=(5,3))\nplt.bar(torch.arange(10), histo, width=0.9, color='#18b6f4')\nplt.xticks(range(10), 'αβγδεζηθικ')\nplt.xlabel('experiences')\nplt.yticks(range(0, max(counts)+1))\nplt.ylabel('occurrences')\nplt.box(False);\n\n\n\n\nWhen our experience happens to be infinite and multidimensional, let’s force it to be finite, discrete and one-dimensional."
  },
  {
    "objectID": "posts/counter/counter.html#idea-1-quantize-vectors",
    "href": "posts/counter/counter.html#idea-1-quantize-vectors",
    "title": "How To Count Experience",
    "section": "Idea 1: quantize vectors",
    "text": "Idea 1: quantize vectors\nDefine a fixed codebook with \\(V\\) experience prototypes. Given a query experience match the closest prototype using inner product or p-norm, then count prototype identifiers.\nBelow I’m going to show an example of a randomly initialized codebook.\n\nV, D = 16, 32\ntable = nn.Embedding(V, D) \nwords = table.weight.detach().numpy()\nplt.figure(figsize=(12,3))\nplt.imshow(words, interpolation='nearest')\nplt.yticks(range(len(words)), string.printable[:len(words)])\nplt.xticks([2**i for i in range(5)])\nplt.title('Codebook of 16 words, 32 dimensions per word vector')\nplt.colorbar();\n\n\n\n\nNow given a random experience \\(x\\) I’m going to use a fast algorithm to compute pairwise L2 norms with the vocabulary. It’s mentioned in Kim, Papamakarios and Mnih, 2020 and this CSCS tutorial on HPC for Python.\n\nx = torch.randn(T, D) # experience\ny = table.weight.data # discrete prototypes\n\nl2_norm_similarity_slow = torch.norm(x[:, None, :] - y[None, :, :], p=2, dim=-1) # (T, V)\nl2_norm_similarity_fast = ((x*x).sum(dim=-1)[:,None] - 2*(x @ y.T) + (y*y).sum(dim=-1)[None, :]).abs().sqrt() # (T,V)\ntorch.allclose(l2_norm_similarity_slow, l2_norm_similarity_fast)\n\nTrue\n\n\nNow argmin gives us our hard assignment to codebook ids:\n\nl2_norm_similarity_fast.argmin(dim=-1)\n\ntensor([ 4, 10,  6,  7, 15,  8,  8])\n\n\n“Good” prototype vectors can be estimated from data using algorithms like LBG, Lloyd’s (aka k-means), CBOW in Mikolov et al, 2013, next word prediction, etc.\nHowever, sometimes random codebooks are enough.\nIn reinforcement learning, random projections of observations are used in a variant of artificial curiosity. An agent is rewarded proportional to the prediction error of a random projection of the state in Burda et al, 2018.\nConsistency objective of random targets is used to bootstrap self-supervised representations in Tarvainen & Valpola, 2017. Random projection quantization is used for large scale self-supervised learning in speech recognition in Chiu et al, 2022 to make learning targets.\nHard assignment, however, is not differentiable. To backpropagate through hard assignment you need to use algorithms like REINFORCE. Such estimation gives very noisy gradient estimates: in REINFORCE you only mark assignments that “worked” and ignore negative information."
  },
  {
    "objectID": "posts/counter/counter.html#idea-2-count-softly",
    "href": "posts/counter/counter.html#idea-2-count-softly",
    "title": "How To Count Experience",
    "section": "Idea 2: count softly",
    "text": "Idea 2: count softly\nMatching can be done against noisy versions of vector observations. Example below uses dot product attention to match and count.\nAlternatively 2-norm can be used instead of the dot product. L2 attention has bounded gradient, as shown in Kim, Papamakarios and Mnih, 2020. This fact can be useful later.\n\nkeys = table(experience) # keys is the experience sequence of length T\nquery = table(torch.arange(len(words))) # keys are the whole vocabulary V\natt = (keys @ query.T) / math.sqrt(D) # (T, V)\natt = att.softmax(dim=-1)\nsoft_counts = att.sum(dim=0)\n\nfig, (axl,axr) = plt.subplots(1, 2, figsize=(12, 3))\naxl.imshow(att)\n\naxl.set_yticks(ticks=range(len(experience)), labels=experience.tolist());\naxl.set_xticks(ticks=range(len(query)), labels=string.printable[:len(query)]);\naxl.set_ylabel('experience is key')\naxl.set_xlabel('vocabulary is query')\naxr.bar(range(len(query)), soft_counts.round().tolist(), alpha=0.3)\naxr.bar(range(len(query)), soft_counts.tolist(), alpha=0.3)\naxr.set_xticks(ticks=range(len(query)), labels=string.printable[:len(query)]);\naxr.set_yticks(ticks=range(3));\naxr.set_ylabel('(rounded) soft counts')\naxr.set_xlabel('vocabulary');"
  },
  {
    "objectID": "posts/counter/counter.html#idea-3-running-counts",
    "href": "posts/counter/counter.html#idea-3-running-counts",
    "title": "How To Count Experience",
    "section": "Idea 3: running counts",
    "text": "Idea 3: running counts\nWe perform counting recurrently, updating a hidden state of word counts. This downgrades complexity of updates from quadratic to linear.\nOnce observations are discrete (e.g. turned discrete through elaborate quantization), this can be implemented with cumsum.\n\nB, T, V = 2, 7, 4\nobservations = torch.randint(0, V, (B, T)).view(-1)\none_hot_observations = F.one_hot(observations).view(B,T,V)\nrunning_counts = one_hot_observations.cumsum(dim=-2)\nrunning_counts\n\ntensor([[[0, 1, 0, 0],\n         [0, 2, 0, 0],\n         [0, 3, 0, 0],\n         [1, 3, 0, 0],\n         [1, 3, 1, 0],\n         [1, 3, 2, 0],\n         [2, 3, 2, 0]],\n\n        [[0, 0, 1, 0],\n         [0, 0, 1, 1],\n         [0, 0, 1, 2],\n         [1, 0, 1, 2],\n         [1, 0, 1, 3],\n         [2, 0, 1, 3],\n         [2, 1, 1, 3]]])"
  },
  {
    "objectID": "posts/counter/counter.html#idea-4-abstract-over-embedding-tables",
    "href": "posts/counter/counter.html#idea-4-abstract-over-embedding-tables",
    "title": "How To Count Experience",
    "section": "Idea 4: abstract over embedding tables",
    "text": "Idea 4: abstract over embedding tables\nDifferent environments provide different possible “vocabularies” of experience. All vocabularies are sampled from \\(\\mathcal{N}(0,I)\\). Let’s train a recurrent network to predict how many times it has seen a given input.\n\n# spot init.normal_\nnn.Embedding.reset_parameters??\n\nSignature: nn.Embedding.reset_parameters(self) -&gt; None\nDocstring: &lt;no docstring&gt;\nSource:   \n    def reset_parameters(self) -&gt; None:\n        init.normal_(self.weight)\n        self._fill_padding_idx_with_zero()\nFile:      ~/curiosity/.venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py\nType:      function\n\n\n\ndef make_batch():\n    \"\"\"\n    Generate random observation sequences and a class index\n    that tells if we've seen the observation once (class 0), twice (class 1) or many times (class 2) before.\n\n    Returns:\n    inputs (torch.Tensor): A tensor of shape (B, T, D) containing the embeddings\n    of the observation sequences, where B is the batch size, T is the sequence length,\n    and D is the embedding dimension.\n\n    targets (torch.Tensor): A tensor of shape (B, T) containing the class index,\n    where B is the batch size and T is the sequence length.\n    \"\"\"\n    B, T, D, Vlocal = 32, 7, 32, 4\n    Vglobal = B*Vlocal\n    local_word_ids = torch.randint(0, 4, (B, T,))\n    table = nn.Embedding(Vglobal, D)\n    global_word_ids = torch.arange(B)[:, None]*4 + local_word_ids\n    inputs = table(global_word_ids)\n    current_input = F.one_hot(local_word_ids.view(-1), num_classes=Vlocal).view(B, T, Vlocal)\n    counts = current_input.cumsum(dim=1)\n\n    # how many times have we seen the current input so far? one, two or many\n    targets = (counts * current_input).clamp(0, 3)\n    targets = targets.sum(-1) - 1\n    return inputs, targets\n\nI’ll be using LSTM that has an inductive bias towards counting thanks to its forget gates. This has been mentioned in Deletang et al, 2023 putting LSTM in context with other architectures.\n\nclass Counter(nn.Module):\n    def __init__(self, dim=32, hidden=512):\n        super().__init__()\n        self.readin = nn.Linear(dim, hidden)\n        self.rnn = nn.LSTM(hidden, hidden, batch_first=True)\n        self.readout = nn.Linear(hidden, 3) # one, two or many times\n\n    def forward(self, x):\n        x = self.readin(x)\n        x, _ = self.rnn(x)\n        x = self.readout(x)\n        return x\n\ntorch.set_grad_enabled(True)\ndevice = 'cuda:1'\ncounter = Counter().to(device)\noptimizer = torch.optim.Adam(counter.parameters(), lr=1e-3)\n\nN = 10000\nlosses = torch.zeros(N)\n\nfor step in range(1,N+1):\n    inputs, targets = make_batch()\n    inputs, targets = inputs.to(device), targets.to(device)\n    logits = counter(inputs)\n    loss = F.cross_entropy(logits.view(-1, 3), targets.view(-1))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    losses[step-1] = loss.item()\n    if step &gt; 1 and math.log10(step) % 1 == 0:\n        plt.figure(figsize=(6,2))\n        plt.plot(losses[:step-1].numpy())\n        plt.title(f'step {step}: loss {loss:.5f}')\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, let’s test the counter.\n\ninputs, targets = make_batch()\ncounter(inputs[0, :].to(device)).argmax(dim=-1), targets[0, :].to(device)\n\n(tensor([0, 1, 0, 2, 1, 2, 0], device='cuda:1'),\n tensor([0, 1, 0, 2, 1, 2, 0], device='cuda:1'))\n\n\nThis almost gives us a generic counter of experience taken from a standard 32-dimensional normal distribution.\nHow to predict actual counts? One way is to perform regression to numeric targets.\nIn classification land we can take a softmax, however there is no inductive bias in the softmax towards relationships between output classes, which is why I took classes one, two and many to demonstrate the concept to begin with.\nA way to add such bias is to use windowed label smoothing around the target (a trick from somewhere on kaggle, I’ll need to find a link to it). Another way is to use mixture of logistics from Salimans et al, 2017."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Hello World",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/meta/motivation.html",
    "href": "posts/meta/motivation.html",
    "title": "Sparsely supervised learning needs faster learning algorithms",
    "section": "",
    "text": "Sequence transduction tasks require large parallel corpora to get \\(p(y|x)\\). Small changes to translation rules require large updates to data and tuning. How to make models adapt online with little data?\n\n\nCode\nimport matplotlib.pyplot as plt\nimport torch\nx = torch.linspace(-5,5,1000)\np_x = torch.exp(-0.5*x**2)\np_x = p_x/p_x.sum()\np_y = torch.exp(-1.5*(x-1)**2)\np_y = p_y/p_y.sum()\ndivergence = p_x*(p_x/p_y).log()\nplt.axis('off')\nplt.plot(x, p_x/p_x.sum(), color='#011117')\nplt.plot(x, p_y/p_y.sum(), color='#56cbf7')\nplt.plot(x, divergence, color='#16b8f3', linestyle=':');\n\n\n\n\n\nDrifts in target languages (e.g. recently acquired consensus on new spelling or grammar rules, new words) or in corpora curation rules (e.g. decision to include punctuation in speech recognition output) require actions like dataset balancing, retraining or costly hyperparameter retuning to account for substantial changes in the data distribution.\nDrifts in source languages, such as shifts in speaker characteristic like accents or code switching, channel characteristics like environment noise or reverbertaion, or capture device conditions like EMG body sensor positions require extensive multi-condition training efforts (augmentation design) and condition adaptation.\nTo make deep learning work well in all source and target language conditions users need to ensure that all data is properly curated and balanced, on top of having to deal with architecture-specific issues like sequence length generalization or hyperparameter tuning due to dataset size mismatch.\nThe curator is required to decide what parts of data distribution require attention to improve performance. The objective of getting the system to perform better on a held out test set can be with odds to the objective of equally representing all users.\nCuration of consistent parallel corpora is a tedious task that requires that a large batch of updates (e.g. 1-10 hours worth of sentences) is done offline, and only then a model is retrained or fine-tuned using a slow learning algorithm like SGD. Getting an SGD-based system to immediately adjust its output based on a single training example (e.g. correction of a single) word is very hard. Even though SGD converges exponentially fast.\nCurrent deep learning systems work quite well on estimating densities like \\(p(x)\\) and \\(p(y)\\) and with addition of discrete tokenizers it becomes much easier to estimate \\(p(x,y)\\) jointly.\nIt’s often easy small amounts of \\(x\\) and \\(y\\) and perform density adaptation of large pretrained models with adapters.\nAdaptation of translation rules seems to be much harder to get right and requires a lot of tweaking. Given densities, we would like to perform translation, synthesis or recognition. Can we delay binding of translation rules so that users can bring their own? Learn what it means to learn to translate separately from actual translation rules."
  },
  {
    "objectID": "posts/meta-ar/thing.html",
    "href": "posts/meta-ar/thing.html",
    "title": "An Autoregressive Meta Learner",
    "section": "",
    "text": "Procedurally-generated environment consists of a small set of \\(K\\) input symbols and a set of \\(K\\) output symbols. The meta learner remembers input-output symbol mappings and is expected to generalize over the sets of symbols.\n\n# aaaabbbb\n\nimport torch.nn as nn\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm import trange\n\n\nI, O = 16, 32\nK = 8\nT = 24\nNbatch = 31\nNalphabets_train, Nalphabets_valid = 10000, 100\n\ntrain_inputs = [nn.Embedding(K, I) for _ in range(Nalphabets_train)]\ntrain_outputs = [nn.Embedding(K, O) for _ in range(Nalphabets_train)]\n\nvalid_inputs = [nn.Embedding(K, I) for _ in range(Nalphabets_valid)]\nvalid_outputs = [nn.Embedding(K, O) for _ in range(Nalphabets_valid)]\n\npad = torch.zeros(Nbatch, O)\n\n\ndef make_sequences(inputs, generator=None):\n    alphabets = torch.randint(0, len(inputs), (Nbatch,), generator=generator)\n    sequences = torch.randint(0, K, (Nbatch, T), generator=generator)\n    return alphabets, sequences\n\n@torch.inference_mode()\ndef make_batch(inputs, outputs, generator=None):\n    alphabets, sequences = make_sequences(inputs, generator)\n\n    all_inputs = torch.stack([\n        torch.stack([inputs[i](s) for s in seq])\n        for i, seq in zip(alphabets, sequences)\n    ]).transpose(0,1)\n    all_targets = torch.stack([\n        torch.stack([pad[0]] + [outputs[i](s) for s in seq])\n        for i, seq in zip(alphabets, sequences)\n    ]).transpose(0,1)\n\n    nar_x = torch.cat([all_inputs, torch.zeros_like(all_targets[:-1])], dim=-1)\n    x = torch.cat([all_inputs, all_targets[:-1]], dim=-1)\n    return x, nar_x, all_targets[1:]\n\n\n# magic sequence\nmake_sequences(valid_inputs, generator=torch.Generator().manual_seed(0))[1][0]\n\ntensor([4, 3, 0, 3, 5, 6, 7, 7, 0, 2, 3, 0, 1, 3, 5, 3, 3, 6, 7, 0, 1, 1, 1, 7])\n\n\n\nclass Model(nn.Module):\n    def __init__(self, hidden=512):\n        super().__init__()\n        self.readin = nn.Linear(I+O, hidden)\n        self.readout = nn.Linear(hidden, O)\n        self.hidden = hidden\n        self.rnn = nn.LSTM(hidden, hidden, num_layers=1)\n\n    def forward(self, x):\n        return self.readout(self.rnn(self.readin(x))[0])\n\n\ndevice = 'cuda:1'\nmodel = Model().to(device)\nnar_model = Model().to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nnar_optimizer = torch.optim.Adam(nar_model.parameters(), lr=0.001)\n\nNsteps = 10000\ntrain_losses = torch.zeros(Nsteps)\nvalid_losses = torch.zeros(Nsteps)\nvalid_stepwise_losses = torch.zeros(Nsteps, T, Nbatch)\n\nnar_train_losses = torch.zeros(Nsteps)\nnar_valid_losses = torch.zeros(Nsteps)\nnar_valid_stepwise_losses = torch.zeros(Nsteps, T, Nbatch)\n\n\nwith trange(Nsteps) as t:\n    for step in t:\n        optimizer.zero_grad()\n        nar_optimizer.zero_grad()\n\n        x, nar_x, y_targets = make_batch(train_inputs, train_outputs)\n\n        y_targets = y_targets.to(device)\n        y = model(x.to(device))\n        \n        loss = (y - y_targets.detach()).pow(2).mean()\n        loss.backward()\n        optimizer.step()\n        train_losses[step] = loss.item()\n\n        nar_y = nar_model(nar_x.to(device))\n\n        nar_loss = (nar_y - y_targets.detach()).pow(2).mean()\n        nar_loss.backward()\n        nar_optimizer.step()\n        nar_train_losses[step] = nar_loss.item()\n\n        t.set_postfix(loss=loss.item(), nar_loss=nar_loss.item())\n\n        with torch.inference_mode():\n            sequences = make_sequences(valid_inputs, generator=torch.Generator().manual_seed(0))[1]\n            x_valid, nar_x_valid, y_targets_valid = make_batch(valid_inputs, valid_outputs, generator=torch.Generator().manual_seed(0))\n            y_targets_valid = y_targets_valid.to(device)\n            y_valid = model(x_valid.to(device))\n            nar_y_valid = nar_model(nar_x_valid.to(device))\n\n            loss_valid = (y_valid - y_targets_valid).pow(2).mean()\n            nar_loss_valid = (nar_y_valid - y_targets_valid).pow(2).mean()\n\n            loss_valid_stepwise = (y_valid - y_targets_valid).pow(2).mean(dim=-1)\n            valid_losses[step] = loss_valid.item()\n            valid_stepwise_losses[step, :, :] = loss_valid_stepwise.cpu()\n\n            nar_loss_valid_stepwise = (nar_y_valid - y_targets_valid).pow(2).mean(dim=-1)\n            nar_valid_losses[step] = nar_loss_valid.item()\n            nar_valid_stepwise_losses[step, :, :] = nar_loss_valid_stepwise.cpu()\n\n        if step and step % 100 == 0:\n            fig, (axl, axc, axr) = plt.subplots(1, 3, figsize=(16, 4))\n\n            axl.plot(train_losses[:step], color='blue')\n            axl.plot(valid_losses[:step], color='orange')\n            axl.plot(nar_train_losses[:step], linestyle='--', color='blue')\n            axl.plot(nar_valid_losses[:step], linestyle='--', color='orange')\n\n            axc.plot(torch.arange(T), valid_stepwise_losses[step, :, 0], color='blue', alpha=0.5, marker='x')\n            for (i, j, text) in zip(torch.arange(T), valid_stepwise_losses[step, :, 0], sequences[0]):\n                axc.text(i, j, f'{text}', color='blue')\n\n            axc.plot(torch.arange(T), nar_valid_stepwise_losses[step, :, 0], color='blue', alpha=0.2, marker='x', linestyle='--')\n    \n            axc.set_title(''.join([str(x) for x in make_sequences(valid_inputs, generator=torch.Generator().manual_seed(0))[1][0].tolist()]))\n\n            axr.plot(torch.arange(T), valid_stepwise_losses[step, :, 1], color='orange', alpha=0.5, marker='x')\n            for (i, j, text) in zip(torch.arange(T), valid_stepwise_losses[step, :, 1], sequences[1]):\n                axr.text(i, j, f'{text}', color='orange')\n\n            axr.plot(torch.arange(T), nar_valid_stepwise_losses[step, :, 1], color='orange', alpha=0.2, marker='x', linestyle='--')\n\n            axr.set_title(''.join([str(x) for x in make_sequences(valid_inputs, generator=torch.Generator().manual_seed(0))[1][1].tolist()]))\n            plt.show()\n\n  1%|          | 100/10000 [00:03&lt;04:56, 33.39it/s, loss=0.95, nar_loss=1.01]    2%|▏         | 200/10000 [00:06&lt;05:01, 32.48it/s, loss=0.937, nar_loss=1]      3%|▎         | 300/10000 [00:09&lt;04:59, 32.37it/s, loss=0.942, nar_loss=0.999]  4%|▍         | 400/10000 [00:13&lt;04:53, 32.70it/s, loss=0.917, nar_loss=0.982]  5%|▌         | 500/10000 [00:16&lt;04:46, 33.15it/s, loss=0.937, nar_loss=0.997]  6%|▌         | 600/10000 [00:19&lt;04:43, 33.19it/s, loss=0.948, nar_loss=1.01]   7%|▋         | 700/10000 [00:23&lt;04:43, 32.79it/s, loss=0.923, nar_loss=0.992]  8%|▊         | 800/10000 [00:26&lt;04:44, 32.34it/s, loss=0.931, nar_loss=1.01]   9%|▉         | 900/10000 [00:30&lt;04:40, 32.39it/s, loss=0.926, nar_loss=0.998] 10%|█         | 1000/10000 [00:33&lt;04:34, 32.75it/s, loss=0.898, nar_loss=1.01] 11%|█         | 1100/10000 [00:37&lt;04:32, 32.66it/s, loss=0.849, nar_loss=0.996] 12%|█▏        | 1200/10000 [00:40&lt;04:32, 32.33it/s, loss=0.819, nar_loss=0.982] 13%|█▎        | 1300/10000 [00:44&lt;04:28, 32.37it/s, loss=0.766, nar_loss=0.958] 14%|█▍        | 1400/10000 [00:47&lt;04:26, 32.22it/s, loss=0.771, nar_loss=0.981] 15%|█▌        | 1500/10000 [00:51&lt;04:19, 32.74it/s, loss=0.768, nar_loss=1]     16%|█▌        | 1600/10000 [00:54&lt;04:17, 32.67it/s, loss=0.744, nar_loss=0.959] 17%|█▋        | 1700/10000 [00:57&lt;04:15, 32.48it/s, loss=0.744, nar_loss=1.02]  18%|█▊        | 1800/10000 [01:01&lt;04:13, 32.35it/s, loss=0.729, nar_loss=0.997] 19%|█▉        | 1900/10000 [01:05&lt;04:08, 32.59it/s, loss=0.719, nar_loss=0.995] 20%|██        | 2000/10000 [01:08&lt;04:09, 32.02it/s, loss=0.722, nar_loss=1]     21%|██        | 2100/10000 [01:12&lt;04:06, 32.01it/s, loss=0.698, nar_loss=0.981] 22%|██▏       | 2200/10000 [01:15&lt;04:01, 32.25it/s, loss=0.702, nar_loss=0.985] 23%|██▎       | 2300/10000 [01:19&lt;03:55, 32.66it/s, loss=0.67, nar_loss=0.995]  24%|██▍       | 2400/10000 [01:22&lt;03:50, 32.98it/s, loss=0.677, nar_loss=1.01]  25%|██▌       | 2500/10000 [01:26&lt;03:52, 32.28it/s, loss=0.665, nar_loss=0.979] 26%|██▌       | 2600/10000 [01:29&lt;03:47, 32.47it/s, loss=0.676, nar_loss=1.01]  27%|██▋       | 2700/10000 [01:33&lt;03:45, 32.35it/s, loss=0.667, nar_loss=0.999] 28%|██▊       | 2800/10000 [01:36&lt;03:38, 32.91it/s, loss=0.663, nar_loss=0.986] 29%|██▉       | 2900/10000 [01:40&lt;03:37, 32.69it/s, loss=0.655, nar_loss=0.985] 30%|███       | 3000/10000 [01:43&lt;03:37, 32.19it/s, loss=0.669, nar_loss=0.992] 31%|███       | 3100/10000 [01:47&lt;03:33, 32.31it/s, loss=0.668, nar_loss=1]     32%|███▏      | 3200/10000 [01:50&lt;03:25, 33.16it/s, loss=0.675, nar_loss=1.02]  33%|███▎      | 3300/10000 [01:54&lt;03:27, 32.22it/s, loss=0.662, nar_loss=0.978] 34%|███▍      | 3400/10000 [01:57&lt;03:24, 32.28it/s, loss=0.664, nar_loss=0.994] 35%|███▌      | 3500/10000 [02:01&lt;03:20, 32.40it/s, loss=0.637, nar_loss=0.985] 36%|███▌      | 3600/10000 [02:05&lt;03:19, 32.11it/s, loss=0.658, nar_loss=1]     37%|███▋      | 3700/10000 [02:08&lt;03:15, 32.30it/s, loss=0.658, nar_loss=0.999] 38%|███▊      | 3799/10000 [02:12&lt;03:10, 32.48it/s, loss=0.641, nar_loss=0.968] 39%|███▉      | 3899/10000 [02:15&lt;03:08, 32.39it/s, loss=0.63, nar_loss=0.997]  40%|███▉      | 3999/10000 [02:19&lt;03:05, 32.30it/s, loss=0.641, nar_loss=0.989] 41%|████      | 4099/10000 [02:23&lt;02:59, 32.82it/s, loss=0.641, nar_loss=0.991] 42%|████▏     | 4199/10000 [02:26&lt;02:59, 32.30it/s, loss=0.615, nar_loss=1.01]  43%|████▎     | 4299/10000 [02:30&lt;02:56, 32.35it/s, loss=0.619, nar_loss=0.984] 44%|████▍     | 4399/10000 [02:33&lt;02:53, 32.36it/s, loss=0.616, nar_loss=0.995] 45%|████▍     | 4499/10000 [02:37&lt;02:49, 32.43it/s, loss=0.63, nar_loss=1.01]   46%|████▌     | 4599/10000 [02:41&lt;02:46, 32.41it/s, loss=0.603, nar_loss=0.962] 47%|████▋     | 4699/10000 [02:44&lt;02:43, 32.50it/s, loss=0.627, nar_loss=0.962] 48%|████▊     | 4799/10000 [02:48&lt;02:42, 32.10it/s, loss=0.634, nar_loss=0.993] 49%|████▉     | 4899/10000 [02:52&lt;02:37, 32.29it/s, loss=0.611, nar_loss=0.987] 50%|████▉     | 4999/10000 [02:55&lt;02:34, 32.35it/s, loss=0.602, nar_loss=0.955] 51%|█████     | 5099/10000 [02:59&lt;02:31, 32.33it/s, loss=0.631, nar_loss=0.99]  52%|█████▏    | 5199/10000 [03:03&lt;02:26, 32.70it/s, loss=0.607, nar_loss=0.979] 53%|█████▎    | 5299/10000 [03:06&lt;02:25, 32.37it/s, loss=0.611, nar_loss=0.968] 54%|█████▍    | 5399/10000 [03:10&lt;02:20, 32.70it/s, loss=0.615, nar_loss=0.998] 55%|█████▍    | 5499/10000 [03:13&lt;02:18, 32.48it/s, loss=0.595, nar_loss=0.955] 56%|█████▌    | 5599/10000 [03:17&lt;02:15, 32.47it/s, loss=0.617, nar_loss=0.994] 57%|█████▋    | 5699/10000 [03:21&lt;02:12, 32.49it/s, loss=0.59, nar_loss=0.954]  58%|█████▊    | 5799/10000 [03:24&lt;02:09, 32.38it/s, loss=0.591, nar_loss=0.951] 59%|█████▉    | 5899/10000 [03:28&lt;02:06, 32.46it/s, loss=0.631, nar_loss=0.999] 60%|█████▉    | 5999/10000 [03:32&lt;02:03, 32.43it/s, loss=0.629, nar_loss=1]     61%|██████    | 6099/10000 [03:35&lt;02:00, 32.47it/s, loss=0.597, nar_loss=0.975] 62%|██████▏   | 6199/10000 [03:39&lt;01:57, 32.41it/s, loss=0.598, nar_loss=0.988] 63%|██████▎   | 6299/10000 [03:43&lt;01:54, 32.39it/s, loss=0.593, nar_loss=0.967] 64%|██████▍   | 6399/10000 [03:47&lt;01:50, 32.49it/s, loss=0.632, nar_loss=1]     65%|██████▍   | 6499/10000 [03:50&lt;01:47, 32.51it/s, loss=0.613, nar_loss=0.981] 66%|██████▌   | 6599/10000 [03:54&lt;01:44, 32.46it/s, loss=0.614, nar_loss=0.981] 67%|██████▋   | 6699/10000 [03:58&lt;01:41, 32.65it/s, loss=0.611, nar_loss=0.983] 68%|██████▊   | 6799/10000 [04:01&lt;01:38, 32.34it/s, loss=0.569, nar_loss=0.939] 69%|██████▉   | 6899/10000 [04:05&lt;01:35, 32.42it/s, loss=0.605, nar_loss=0.998] 70%|██████▉   | 6999/10000 [04:09&lt;01:33, 32.07it/s, loss=0.582, nar_loss=0.969] 71%|███████   | 7099/10000 [04:13&lt;01:29, 32.28it/s, loss=0.61, nar_loss=0.978]  72%|███████▏  | 7199/10000 [04:16&lt;01:25, 32.80it/s, loss=0.588, nar_loss=0.969] 73%|███████▎  | 7299/10000 [04:20&lt;01:23, 32.51it/s, loss=0.6, nar_loss=0.985]   74%|███████▍  | 7399/10000 [04:24&lt;01:18, 32.93it/s, loss=0.604, nar_loss=0.969] 75%|███████▍  | 7499/10000 [04:28&lt;01:17, 32.43it/s, loss=0.618, nar_loss=0.975] 76%|███████▌  | 7599/10000 [04:31&lt;01:12, 32.96it/s, loss=0.598, nar_loss=0.976] 77%|███████▋  | 7699/10000 [04:35&lt;01:09, 32.98it/s, loss=0.589, nar_loss=0.998] 78%|███████▊  | 7799/10000 [04:39&lt;01:07, 32.70it/s, loss=0.565, nar_loss=0.97]  79%|███████▉  | 7899/10000 [04:43&lt;01:04, 32.58it/s, loss=0.592, nar_loss=0.991] 80%|███████▉  | 7999/10000 [04:46&lt;01:01, 32.60it/s, loss=0.576, nar_loss=0.964] 81%|████████  | 8099/10000 [04:50&lt;00:58, 32.75it/s, loss=0.583, nar_loss=0.97]  82%|████████▏ | 8199/10000 [04:54&lt;00:55, 32.47it/s, loss=0.587, nar_loss=0.993] 83%|████████▎ | 8299/10000 [04:58&lt;00:52, 32.49it/s, loss=0.574, nar_loss=0.966] 84%|████████▍ | 8399/10000 [05:02&lt;00:49, 32.24it/s, loss=0.591, nar_loss=0.972] 85%|████████▍ | 8499/10000 [05:05&lt;00:46, 32.23it/s, loss=0.564, nar_loss=0.952] 86%|████████▌ | 8599/10000 [05:09&lt;00:43, 32.36it/s, loss=0.584, nar_loss=0.972] 87%|████████▋ | 8699/10000 [05:13&lt;00:40, 32.22it/s, loss=0.579, nar_loss=0.948] 88%|████████▊ | 8799/10000 [05:17&lt;00:36, 32.83it/s, loss=0.584, nar_loss=0.979] 89%|████████▉ | 8899/10000 [05:21&lt;00:33, 32.51it/s, loss=0.606, nar_loss=0.981] 90%|████████▉ | 8999/10000 [05:25&lt;00:30, 32.46it/s, loss=0.574, nar_loss=0.962] 91%|█████████ | 9099/10000 [05:29&lt;00:27, 32.38it/s, loss=0.567, nar_loss=0.966] 92%|█████████▏| 9199/10000 [05:32&lt;00:24, 32.41it/s, loss=0.569, nar_loss=0.977] 93%|█████████▎| 9299/10000 [05:36&lt;00:21, 32.48it/s, loss=0.527, nar_loss=0.941] 94%|█████████▍| 9399/10000 [05:40&lt;00:18, 32.39it/s, loss=0.566, nar_loss=0.973] 95%|█████████▍| 9499/10000 [05:44&lt;00:15, 32.46it/s, loss=0.577, nar_loss=0.979] 96%|█████████▌| 9599/10000 [05:48&lt;00:12, 32.46it/s, loss=0.555, nar_loss=0.967] 97%|█████████▋| 9699/10000 [05:52&lt;00:09, 32.53it/s, loss=0.572, nar_loss=0.973] 98%|█████████▊| 9799/10000 [05:56&lt;00:06, 32.59it/s, loss=0.557, nar_loss=0.987] 99%|█████████▉| 9899/10000 [06:00&lt;00:03, 31.94it/s, loss=0.586, nar_loss=0.943]100%|██████████| 10000/10000 [06:04&lt;00:00, 27.47it/s, loss=0.586, nar_loss=0.964]"
  },
  {
    "objectID": "posts/meta/transducer.html",
    "href": "posts/meta/transducer.html",
    "title": "Meta Sequence Transducer",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ntorch.manual_seed(42);\n\n\nWe have two datasets of disjoint discrete integer sequences \\(L\\) and \\(R\\). They represent sentences in different languages with no common words.\nWe do not know correct possible translations from one sequence to another, however we would like to let the user of a system propose their rules of translation. We would like to learn an algorithm to rewrite sequences in one language into sequences in another from examples.\nLet’s define a generator of languages and translation examples to train our metalearner on:\n\ndef make_sequence(K=10, L=6, R=6, T=3):\n    \"\"\"Make a (K-1)-shot R-way T-step training sequences.\n    Assumes a latent language defined as a mapping between fixed permutations of alphabets L and R\n    and produces K usage examples of the language.\n    \"\"\"\n    soh, stx = L+R, L+R+1\n\n    vocabR = [[x] for x in (torch.randperm(R) + L)]\n    vocabL = [[x] for x in (torch.randperm(L))]\n\n    # assemble source sentences\n    sources = torch.randint(0, len(vocabL), (K, T))\n    source_sequences = [\n        [token for word in source_sequence for token in vocabL[word]] \n        for source_sequence in sources\n    ]\n\n    # assemble target sentences by translating source\n    target_sequences = [\n        [token for word in source_sequence for token in vocabR[word]]\n        for source_sequence in sources\n    ]\n\n    # format training sequences\n    training_sequence = [tok for s,t  in zip(source_sequences, target_sequences)\n                         for tok in [soh] + s + [stx] + t] + [soh]\n    return torch.tensor(training_sequence)\n\nLet’s define our meta RNN:\n\nN, D, L, R = 32, 512, 6, 6\nsoh, stx, pad = L+R, L+R+1, L+R+2\n\nclass LM(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.words = nn.Embedding(L+R+3, D, padding_idx=pad)\n        self.rnn = nn.LSTM(D, 1024, num_layers=1, batch_first=True)\n        self.classifier = nn.Linear(1024, L+R+3)\n\n    def forward(self, inputs):\n        x = self.words(inputs)\n        x, _ = self.rnn(x)\n        x = self.classifier(x)\n        return x\n\nNow, let’s metatrain the model. The loss curve on the left shows three different phases of training.\nThe plot on the right show a per token loss plot of the all \\(K=10\\) examples from the first training sequence in a batch. First three tokens are equiprobable, as there is no useful distribution of tokens given in the data.\nThe ␂ token is expected and has a very high probability, and then the remaining three tokens have a probability of 1 when the model learns to perform the task.\nNumber of “hanging” curves suggest how many examples were necessary to learn the language.\n\n\nCode\ndef make_batch(K=10, L=6, R=6, T=3):\n    pad = L+R+2\n\n    return torch.nn.utils.rnn.pad_sequence([make_sequence(K=K, L=L, R=R, T=T) for _ in range(32)], batch_first=True, padding_value=pad)\n\ndevice = 'cuda:1'\nlm = LM().to(device)\n\noptimizer = torch.optim.Adam(lm.parameters(), lr=1e-3)\n\nNsteps = 20000\nlosses = torch.zeros(Nsteps)\n\nfor step in range(Nsteps):\n    batch = make_batch(10, L=L, R=R).to(device)\n    inputs, targets = batch[:, :-1], batch[:, 1:]\n    outputs = lm(inputs)\n    \n    loss = F.cross_entropy(outputs.view(-1, L+R+3), targets.reshape(-1), ignore_index=pad)    \n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    losses[step] = loss.item()\n    if step and step % 1000 == 0:\n        plt.figure(figsize=(6, 2))\n        fig, (axl,axr) = plt.subplots(1, 2, figsize=(12, 2))\n        axl.plot(losses[:step+1].numpy())\n        axr.plot(outputs[0].softmax(-1).max(-1).values.detach().cpu().view(-1,8).numpy().T, label=range(10))\n        l, r = torch.where(targets[0]==stx)[0][-1].item(), torch.where(targets[0]==soh)[0][-1].item()\n        acc = (outputs[0,l:r].argmax(dim=-1) == targets[0,l:r]).sum() / (r-l)\n        plt.title(f'step {step}: loss {loss:.5f}, acc: {acc:.5f}')\n        #plt.legend()\n        plt.show()\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;\n\n\n\n\n\n&lt;Figure size 600x200 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/scan/chunk.html",
    "href": "posts/scan/chunk.html",
    "title": "Chunked Scan",
    "section": "",
    "text": "We have a linear recurrence:\n$ x_t = t x{t-1} + u_t$\nWe would like to evaluate it in chunks of \\(T\\) elements: one chunk is evaluated by one processor. When all chunks are ready, one processor can integrate results of another.\nLet \\(x_{-1}\\) be the final element of the previous chunk. We’re ready to define the chunked recursion inductively:\nThe base case:\n\\(x_0 = \\lambda_0 x_{-1} + u_0\\)\nHere \\(\\bar{x}_0 := \\lambda_0 x_{-1}\\) can be seen as a port, where we will connect the previous chunk. By linearity we can treat \\(x'_0 := u_0\\) as a base case of the chunk.\nUsing associativity we have:\n\\(x_1 = \\lambda_1 \\lambda_0 x_{-1} + \\lambda_1 u_0 + u_1\\)\n$x_T = _{i=1}^{i=T}_i {x}_0 + t x’{T-1} + u_T $\nThis leads us to the following algorithm:\n\ncompute the recurrence for \\(x'_T\\)\ncompute cumulative products (e.g. using a zero-order scan) for \\(\\Lambda_t := \\prod_{i=0}^{i=t}\\lambda_i\\)\nreceive the value of \\(x_{-1}\\) from the previous neighbor\ncompute \\(x_t = \\Lambda_t x_{-1} + x'_t\\)\nsend the value of \\(x_T\\) to the next neighbor\n\nReferences:\n[Ble93] Prefix Sums and Their Applications. Guy E. Blelloch https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf"
  },
  {
    "objectID": "posts/neural-circuits/recurrent.html",
    "href": "posts/neural-circuits/recurrent.html",
    "title": "Neural Circuits",
    "section": "",
    "text": "This is a collection of equations for neural circuits.\n\nFeed Forward\n$ h_t = F(x_t) $\nA feed forward with one hidden layer and a nonlinearity is already a universal approximator, when \\(F(x)_i = \\sigma(\\langle w_i, x \\rangle) = \\sigma(\\sum_j w_{ij} x_j)\\). Here \\(w_i\\) is an i-th row vector of some parameter matrix \\(W\\), and \\(\\sigma\\) is some nonlinearity function.\nSearching for approximations of this form for most functions requires a lot of time. The efficiency of the search depends on the choice of \\(\\sigma\\), the size and initialization (choice of family) of \\(W\\). In practice we would like to add an inductive bias to the computation to reflect the structure of the data.\nAlso, dropping nonlinearities \\(\\sigma\\) is useful for algebra purposes, as linear operations tend to distribute over each other, which allows for efficient design of computations. Nonlinearity can be recovered through other means like autoregression. I’m going to mostly ignore nonlinearities.\nMaking future timesteps dependent on the past gives a recurrent:\n\n\nRecurrent\n\\(h_t = F(x_t) + H(h_{t-1})\\)\nThe nonlinearity is usually applied after \\(+\\). A recurrent network can be seen as a shared weights deep feed forward network where future inputs are added during later layers.\nDeep networks suffer from gradient vanishing or explosion during training. A way to mitigate gradient issues is to replace applications of the chain rule of gradients with the sum rule, like is done in the highway below.\n\n\nHighway\n\\(h_t = C(x_t) \\cdot x_t + T(x_t) \\cdot F(x_t)\\)\nwhere \\(C\\) reads carry gate and \\(T\\) reads transform gate. Circuits in gate position usually use the \\(\\sigma\\) nonlinearity with range 0-1. These gates explicitly control what information is taken from what “branch” of the computation.\nUsing a highway with identity gates gives the residual:\n\n\nResidual\n\\(h_t = x_t + F(x_t)\\)\nThe residual highlights the importance of \\(+\\), as gradient \\(\\nabla\\) is a linear operator that distributes over \\(+\\). \\(h\\) can be thought of a residual stream, with which each layer \\(t\\) communicates by reading and writing.\nCombining a highway with recurrence gives an LSTM. Notably, highways were likely derived by removing recurrence from LSTM however thinking in reverse makes it easier for me personally.\n\n\nLong Short Term Memory\n\\(c_t = C(x_t,h_{t-1}) \\cdot c_{t-1} + T(x_t,h_{t-1}) \\cdot F(x_t,h_{t-1})\\)\n\\(h_t = O(x_t,h_{t-1}) \\cdot c_{t}\\)\nwhere \\(C\\) is also named forget gate, \\(T\\) is input gate, and \\(O\\) is output gate. In this context the gates are recurrent.\nUsing feed forward gates without recurrence makes a quasi LSTM. Quasi LSTM is designed so that equations for future hidden states can be precomputed up front for parallelization.\n\n\n\nIllustration of Gradient Highway"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ε␂",
    "section": "",
    "text": "Chunked Scan\n\n\n\n\n\n\n\nrnn\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nMeta Sequence Transducer\n\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nNeural Circuits\n\n\n\n\n\n\n\nalgebra\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nAn Autoregressive Meta Learner\n\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nSparsely supervised learning needs faster learning algorithms\n\n\n\n\n\n\n\nmisc\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nHow To Count Experience\n\n\n\n\n\n\n\nrl\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\n  \n\n\n\n\nHello World\n\n\n\n\n\n\n\nmisc\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2023\n\n\nVolodymyr Kyrylov\n\n\n\n\n\n\nNo matching items"
  }
]